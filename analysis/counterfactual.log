
  ___  ____  ____  ____  ____ (R)
 /__    /   ____/   /   ____/
___/   /   /___/   /   /___/   15.1   Copyright 1985-2017 StataCorp LLC
  Statistics/Data Analysis            StataCorp
                                      4905 Lakeway Drive
     MP - Parallel Edition            College Station, Texas 77845 USA
                                      800-STATA-PC        http://www.stata.com
                                      979-696-4600        stata@stata.com
                                      979-696-4601 (fax)

Single-user 2-core Stata perpetual license:
       Serial number:  501506203290
         Licensed to:  Miklos Koren
                       CEU MicroData


Notes:
      1.  Stata is running in batch mode.
      2.  Unicode is supported; see help unicode_advice.
      3.  More than 2 billion observations are allowed; see help obs_advice.
      4.  Maximum number of variables is set to 5000; see help set_maxvar.

. do counterfactual.do 

. clear all

. 
. import delimited "../data/derived/crosswalk/industry.csv", varnames(1) clear 
> case(preserve)
(3 vars, 90 obs)

. merge 1:1 industry_code using "../data/clean/industry-employment/industry-emp
> loyment.dta", nogen keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                             2
        from master                         2  
        from using                          0  

    matched                                88  
    -----------------------------------------

. rename employment ces_employment

. tempfile industry

. save `industry', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000001 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000001 saved

. 
. import delimited "../data/derived/crosswalk/2digit_names.csv", varnames(1) cl
> ear case(preserve)
(2 vars, 20 obs)

. tempfile digit2

. save `digit2', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000002 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000002 saved

. 
. do "industry_location_panel.do"

. import delimited "../data/derived/occupation/naics_risk.csv", varnames(1) cle
> ar
(6 vars, 84 obs)

. tempfile occupation

. save `occupation', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000003 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St33878.000003 saved

. 
. use "../data/clean/cbp/zip_code_business_patterns.dta", clear

. merge m:1 industry_code using `occupation', keep(match) nogen

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           464,804  
    -----------------------------------------

. 
end of do-file

. merge m:1 industry_code using `industry', nogen keep(master match) keepusing(
> industry_label ces_employment)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           464,804  
    -----------------------------------------

. 
. * drop hospitals and clinics
. drop if inlist(industry_code, 621, 622)
(15,186 observations deleted)

. 
. * regional employment weight from CBP, sectoral weight from CES
. tempvar sum

. egen `sum' = sum(cond(!missing(population_density,communication_share),employ
> ment,0)), by(industry_code)

. generate employment_weight = cond(!missing(population_density,communication_s
> hare),employment,0)/`sum'*ces_employment
(1,209 missing values generated)

. 
. /* 
> Calibrate epsilon to gamma=1.04 in
> 
> Ciccone, Antonio, and Robert Hall. 1996. “Productivity and the Density of Eco
> nomic Activity.” 
> The American Economic Review 86 (1): 54–70.
> 
> page 62.
> 
> density^agglomeration = density^(epsilon * chi)
> */
. scalar agglomeration = 0.04

. generate LHS = agglomeration * ln(population_density)
(5,984 missing values generated)

. generate RHS = (communication_share/100) * ln(population_density)
(5,984 missing values generated)

. 
. regress LHS RHS [aw=employment_weight]
(sum of wgt is 116,309.746596697)

      Source |       SS           df       MS      Number of obs   =   442,430
-------------+----------------------------------   F(1, 442428)    >  99999.00
       Model |  616.297587         1  616.297587   Prob > F        =    0.0000
    Residual |  1335.23119   442,428  .003017963   R-squared       =    0.3158
-------------+----------------------------------   Adj R-squared   =    0.3158
       Total |  1951.52878   442,429  .004410942   Root MSE        =    .05494

------------------------------------------------------------------------------
         LHS |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         RHS |   .0263435   .0000583   451.90   0.000     .0262292    .0264577
       _cons |   .1821685   .0001805  1009.36   0.000     .1818147    .1825222
------------------------------------------------------------------------------

. scalar epsilon = _b[RHS]

. generate chi = communication_share/100

. generate gamma = chi/(1-chi)

. 
. * Eq 4
. generate contact = population_density^(epsilon*(1-chi))
(5,527 missing values generated)

. 
. * current number of contacts
. summarize contact [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
     contact | 442,887    116498.2    1.098926   .0611887          0    1.28774

. scalar current_contact = r(mean)

. 
. * target contact is half
. scalar target_contact = current_contact * 0.5

. 
. * loop to find the cap
. scalar cap = 10000

. scalar average = current_contact 

. generate counterfactual = .
(449,618 missing values generated)

. while average > target_contact {
  2.         quietly replace counterfactual = min(contact, min(population_densi
> ty, cap)^(epsilon*(1-chi)))
  3.         quietly summarize counterfactual [aw=employment_weight]
  4.         scalar average = r(mean)
  5.         scalar cap = 0.90*cap
  6. }

. 
. generate contact_ratio = counterfactual / contact
(5,984 missing values generated)

. * Eq 6 from the paper
. generate labor_subsidy = 100 - 100 * (1 - chi*contact_ratio) * (contact_ratio
> )^gamma / (1-chi)
(5,984 missing values generated)

. summarize labor_subsidy [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
labor_subs~y | 442,430  116309.747    18.55491   6.770266   3.115181   37.50838

. 
. * compute for nyc
. merge m:1 zip using "nyc_zip.dta", keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                       443,603
        from master                   443,603  (_merge==1)
        from using                          0  (_merge==2)

    matched                             6,015  (_merge==3)
    -----------------------------------------

. generate nyc = (_m==3)

. summarize population_density if nyc==1 [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
population~y |   6,014  3962.41947    19325.86   12222.27          0   57231.17

. summarize labor_subsidy if nyc==1 [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
labor_subs~y |   5,844  3885.88659    21.28615   6.529398   5.400251   37.50838

. 
. do "aggregate2digit.do"

. generate naics_2d = int(industry_code/10)

. replace naics_2d = 31 if (naics_2d>=31) & (naics<=33)
(25,843 real changes made)

. replace naics_2d = 44 if (naics_2d>=44) & (naics<=45)
(30,239 real changes made)

. replace naics_2d = 48 if (naics_2d>=48) & (naics<=49)
(3,411 real changes made)

. 
end of do-file

. * weighted cost ratio
. replace labor_subsidy = labor_subsidy * employment_weight
(443,634 real changes made, 1,204 to missing)

. * only add up ces_employment once per industry
. egen tag = tag(industry_code)

. 
. collapse (sum) labor_subsidy employment_weight, by(naics_2d)

. * merge on names
. merge 1:1 naics_2d using `digit2', nogen keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                                19  
    -----------------------------------------

. 
. replace labor_subsidy = round(labor_subsidy/employment_weight, 0.1)
(19 real changes made)

. rename employment_weight employment

. replace employment = round(employment)
(19 real changes made)

. 
. * calculate weighted average
. summarize labor_subsidy [fw=employment], meanonly

. scalar average = r(mean)

. scalar N = r(N)

. 
. gsort -labor_subsidy

. 
. * add a row for average
. set obs 20
number of observations (_N) was 19, now 20

. replace industry_label = "Average" in 20
(1 real change made)

. replace labor_subsidy = average in 20
(1 real change made)

. replace employment = N in 20
(1 real change made)

. 
. order industry_label labor_subsidy employment

. export delimited "cost_by_naics2.csv", replace
file cost_by_naics2.csv saved

. 
end of do-file
